# -*- coding: utf-8 -*-
"""ParquetFileUpload.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QW-EjSsYJO7OQrxbSLKojHvMb4G6SFOW
"""

import boto3
import os
import argparse


def upload_folder_to_s3(local_folder, bucket_name, s3_folder):
    session = boto3.Session(profile_name='EngineerRole')
    s3_client = session.client('s3')
    for root, dirs, files in os.walk(local_folder):
        print(f"List of files to be uploaded: {files}")
        for file in files:
            local_path = os.path.join(root, file)
            file_details = file.split("_")
            table_name = file_details[0]
            year = file_details[1][:4]
            month = file_details[1][4:6]
            s3_path = f"{s3_folder}/{table_name}/year={year}/month={month}/{file}"
            try:
                s3_client.upload_file(local_path, bucket_name, s3_path)
                print(f"Uploaded {local_path} to s3://{bucket_name}/{s3_path}")
            except Exception as e:
                print(f"Error uploading {local_path}: {e}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Extract data from API and save as CSV")
    parser.add_argument('-a', '--localfolder', type=str, required=True, help="path of your local folder to be uploaded")
    parser.add_argument('-s', '--bucketname', type=str, required=True, help="name of the s3 bucket")
    parser.add_argument('-e', '--s3folder', type=str, required=True, help="folder in s3")

    args = parser.parse_args()
    print("Uploading the input folder path to S3 bucket")
    local_folder = args.localfolder
    bucket_name = args.bucketname
    s3_folder = args.s3folder
    upload_folder_to_s3(local_folder, bucket_name, s3_folder)
    print("Successfully Uploaded")




